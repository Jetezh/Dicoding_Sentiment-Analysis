{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     UNEXPECTED_EOF_WHILE_READING] EOF occurred in\n",
      "[nltk_data]     violation of protocol (_ssl.c:1006)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in c:\\users\\vega\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: Levenshtein==0.25.1 in c:\\users\\vega\\anaconda3\\lib\\site-packages (from python-Levenshtein) (0.25.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in c:\\users\\vega\\anaconda3\\lib\\site-packages (from Levenshtein==0.25.1->python-Levenshtein) (3.9.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/ariaghora/mpstemmer.git\n",
      "  Cloning https://github.com/ariaghora/mpstemmer.git to c:\\users\\vega\\appdata\\local\\temp\\pip-req-build-dn027jdd\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/ariaghora/mpstemmer.git 'C:\\Users\\vega\\AppData\\Local\\Temp\\pip-req-build-dn027jdd'\n",
      "  fatal: unable to access 'https://github.com/ariaghora/mpstemmer.git/': Could not resolve host: github.com\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × git clone --filter=blob:none --quiet https://github.com/ariaghora/mpstemmer.git 'C:\\Users\\vega\\AppData\\Local\\Temp\\pip-req-build-dn027jdd' did not run successfully.\n",
      "  │ exit code: 128\n",
      "  ╰─> See above for output.\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× git clone --filter=blob:none --quiet https://github.com/ariaghora/mpstemmer.git 'C:\\Users\\vega\\AppData\\Local\\Temp\\pip-req-build-dn027jdd' did not run successfully.\n",
      "│ exit code: 128\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "\n",
    "from io import StringIO\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# download stopwords dan punctuation dari library nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# download mpstemmer dari github ariaghora\n",
    "%pip install python-Levenshtein\n",
    "%pip install --upgrade git+https://github.com/ariaghora/mpstemmer.git\n",
    "from mpstemmer import MPStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad5d42d7-26b3-4b05-84d5-ec7a1630195c</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Opsi pemilihan GOFOOD \"terdekat\" sekarang kura...</td>\n",
       "      <td>2</td>\n",
       "      <td>137</td>\n",
       "      <td>4.89.1</td>\n",
       "      <td>2024-06-26 03:44:12</td>\n",
       "      <td>Hai Kak Christian, mohon maaf atas ketidaknyam...</td>\n",
       "      <td>2024-06-26 09:25:34</td>\n",
       "      <td>4.89.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fcecd263-6061-4de6-b9f7-ecc2608922dc</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Aplikasi sudah sangat baik, tapi saya kecewa, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>4.90.2</td>\n",
       "      <td>2024-07-11 11:37:32</td>\n",
       "      <td>Hai Kak Boy, mohon maaf atas ketidaknyamananny...</td>\n",
       "      <td>2024-07-11 13:44:23</td>\n",
       "      <td>4.90.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1bf37a40-af8c-4d1f-a677-07a46b121241</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Dear gojek..mengapa setelah pembaruan aplikasi...</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>4.90.2</td>\n",
       "      <td>2024-07-17 11:33:53</td>\n",
       "      <td>Hai David Sinaga, mohon maaf ya. Laporan yang ...</td>\n",
       "      <td>2023-07-11 12:44:39</td>\n",
       "      <td>4.90.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a44b1111-44c4-43c6-8c62-828db2c92fe8</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>aplikasinya bosok. Saya order mobil kebaca di ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.90.2</td>\n",
       "      <td>2024-07-18 10:46:23</td>\n",
       "      <td>Hai Kak @Maha Karma, mohon maaf atas ketidakny...</td>\n",
       "      <td>2024-07-18 13:13:06</td>\n",
       "      <td>4.90.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e24b3821-bd15-4ff4-a751-8c221bac3a26</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Saya mau order go car susahnya minta ampun. Pa...</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>4.89.1</td>\n",
       "      <td>2024-06-21 10:04:58</td>\n",
       "      <td>Mohon maaf atas kendala yang dialami, Kak Auli...</td>\n",
       "      <td>2024-06-21 11:26:46</td>\n",
       "      <td>4.89.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId         userName  \\\n",
       "0  ad5d42d7-26b3-4b05-84d5-ec7a1630195c  Pengguna Google   \n",
       "1  fcecd263-6061-4de6-b9f7-ecc2608922dc  Pengguna Google   \n",
       "2  1bf37a40-af8c-4d1f-a677-07a46b121241  Pengguna Google   \n",
       "3  a44b1111-44c4-43c6-8c62-828db2c92fe8  Pengguna Google   \n",
       "4  e24b3821-bd15-4ff4-a751-8c221bac3a26  Pengguna Google   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "3  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0  Opsi pemilihan GOFOOD \"terdekat\" sekarang kura...      2            137   \n",
       "1  Aplikasi sudah sangat baik, tapi saya kecewa, ...      1             57   \n",
       "2  Dear gojek..mengapa setelah pembaruan aplikasi...      1             66   \n",
       "3  aplikasinya bosok. Saya order mobil kebaca di ...      1              1   \n",
       "4  Saya mau order go car susahnya minta ampun. Pa...      1            128   \n",
       "\n",
       "  reviewCreatedVersion                  at  \\\n",
       "0               4.89.1 2024-06-26 03:44:12   \n",
       "1               4.90.2 2024-07-11 11:37:32   \n",
       "2               4.90.2 2024-07-17 11:33:53   \n",
       "3               4.90.2 2024-07-18 10:46:23   \n",
       "4               4.89.1 2024-06-21 10:04:58   \n",
       "\n",
       "                                        replyContent           repliedAt  \\\n",
       "0  Hai Kak Christian, mohon maaf atas ketidaknyam... 2024-06-26 09:25:34   \n",
       "1  Hai Kak Boy, mohon maaf atas ketidaknyamananny... 2024-07-11 13:44:23   \n",
       "2  Hai David Sinaga, mohon maaf ya. Laporan yang ... 2023-07-11 12:44:39   \n",
       "3  Hai Kak @Maha Karma, mohon maaf atas ketidakny... 2024-07-18 13:13:06   \n",
       "4  Mohon maaf atas kendala yang dialami, Kak Auli... 2024-06-21 11:26:46   \n",
       "\n",
       "  appVersion  \n",
       "0     4.89.1  \n",
       "1     4.90.2  \n",
       "2     4.90.2  \n",
       "3     4.90.2  \n",
       "4     4.89.1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import variabel dari modul scraping\n",
    "from PS_Gojek import app_reviews_df\n",
    "\n",
    "# menghapus isi konten yang kosong dan duplikat\n",
    "gojek_clean_df = app_reviews_df.dropna()\n",
    "gojek_clean_df = gojek_clean_df.drop_duplicates()\n",
    "jumlah_ulasan_setelah_hapus_duplikat, jumlah_kolom_setelah_hapus_duplikat = gojek_clean_df.shape\n",
    "gojek_clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Proseccing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data slangwords\n",
    "slangwords = {\n",
    "    'otw': 'on the way',\n",
    "    'pas': 'tepat',\n",
    "    'kzl': 'kesal',\n",
    "    'brg': 'barang',\n",
    "    'dtg': 'datang',\n",
    "    'sygn': 'sayang',\n",
    "    'hrs': 'harus',\n",
    "    'tp': 'tapi',\n",
    "    'kmrn': 'kemarin',\n",
    "    'kmrn': 'kemarin',\n",
    "    'dpt': 'dapat',\n",
    "    'bgs': 'bagus',\n",
    "    'tdk': 'tidak',\n",
    "    'brp': 'berapa',\n",
    "    'gw': 'saya',\n",
    "    'sis': 'sisa',\n",
    "    'bkn': 'bukan',\n",
    "    'kalo': 'kalau',\n",
    "    'tdk': 'tidak',\n",
    "    'blm': 'belum',\n",
    "    'bnyk': 'banyak',\n",
    "    'sih': 'sih',\n",
    "    'jg': 'juga',\n",
    "    'km': 'kilometer',\n",
    "    'gmn': 'gimana',\n",
    "    'bro': 'saudara',\n",
    "    'sis': 'saudari',\n",
    "    'asap': 'secepat mungkin',\n",
    "    'cpt': 'cepat',\n",
    "    'dr': 'dari',\n",
    "    'kli': 'kali',\n",
    "    'emg': 'memang',\n",
    "    'udh': 'sudah',\n",
    "    'plg': 'pulang',\n",
    "    'drmn': 'dari mana',\n",
    "    'aneh': 'aneh',\n",
    "    'malah': 'malah',\n",
    "    'jadi': 'jadi',\n",
    "    'aja': 'saja',\n",
    "    'dlu': 'dulu',\n",
    "    'sinyal': 'signal',\n",
    "    'ngecharge': 'mengisi daya',\n",
    "    'cr': 'cari',\n",
    "    'bisa': 'bisa',\n",
    "    'lho': 'loh',\n",
    "    'yah': 'yah',\n",
    "    'banget': 'sekali',\n",
    "    'loh': 'loh',\n",
    "    'mlm': 'malam',\n",
    "    'pagi': 'pagi',\n",
    "    'siang': 'siang',\n",
    "    'sore': 'sore',\n",
    "    'trs': 'terus',\n",
    "    'sampe': 'sampai',\n",
    "    'skrg': 'sekarang',\n",
    "    'btw': 'by the way',\n",
    "    'punya': 'punya',\n",
    "    'km': 'kamu',\n",
    "    'temen': 'teman',\n",
    "    'dong': 'dong',\n",
    "    'pdhl': 'padahal',\n",
    "    'tlp': 'telepon',\n",
    "    'lg': 'lagi',\n",
    "    'udh': 'sudah',\n",
    "    'klr': 'keluar',\n",
    "    'wkt': 'waktu',\n",
    "    'dmn': 'di mana',\n",
    "    'antri': 'antre',\n",
    "    'lama': 'lama',\n",
    "    'hrg': 'harga',\n",
    "    'apk': 'aplikasi',\n",
    "    'ga': 'tidak',\n",
    "    'tau': 'tahu',\n",
    "    'susah': 'susah',\n",
    "    'mudah': 'mudah',\n",
    "    'error': 'error',\n",
    "    'admin': 'admin',\n",
    "    'cs': 'customer service',\n",
    "    'top': 'terbaik',\n",
    "    'mantap': 'hebat',\n",
    "    'kurir': 'pengantar',\n",
    "    'tarif': 'tarif',\n",
    "    'transaksi': 'transaksi',\n",
    "    'bengkel': 'bengkel',\n",
    "    'bus': 'bus',\n",
    "    'mampir': 'singgah',\n",
    "    'sopir': 'pengemudi',\n",
    "    'taksi': 'taksi',\n",
    "    'ojol': 'ojek online',\n",
    "    'angkot': 'angkutan kota',\n",
    "    'bensin': 'bahan bakar',\n",
    "    'ngebut': 'cepat',\n",
    "    'ngetem': 'menunggu penumpang',\n",
    "    'pelit': 'kikir',\n",
    "    'service': 'layanan',\n",
    "    'promo': 'promosi',\n",
    "    'cod': 'cash on delivery',\n",
    "    'respon': 'tanggapan',\n",
    "    'feedback': 'umpan balik',\n",
    "    'refund': 'pengembalian dana',\n",
    "    'voucher': 'kupon',\n",
    "    'diskon': 'potongan harga',\n",
    "    'murah': 'murah',\n",
    "    'mahal': 'mahal',\n",
    "    'macet': 'macet',\n",
    "    'jemput': 'menjemput',\n",
    "    'antar': 'mengantar',\n",
    "    'tujuan': 'destinasi',\n",
    "    'bonus': 'bonus',\n",
    "    'batal': 'membatalkan',\n",
    "    'delay': 'penundaan',\n",
    "    'reschedule': 'menjadwal ulang',\n",
    "    'rating': 'penilaian',\n",
    "    'review': 'ulasan',\n",
    "    'komentar': 'komentar',\n",
    "    'kualitas': 'kualitas',\n",
    "    'kecewa': 'kecewa',\n",
    "    'puas': 'puas',\n",
    "    'rahasia': 'privasi',\n",
    "    'update': 'pembaruan',\n",
    "    'lapor': 'melaporkan',\n",
    "    'refund': 'pengembalian dana',\n",
    "    'klaim': 'klaim',\n",
    "    'saldo': 'saldo',\n",
    "    'rekap': 'rekapitulasi',\n",
    "    'driver': 'pengemudi',\n",
    "    'partner': 'mitra',\n",
    "    'fasilitas': 'fasilitas',\n",
    "    'kendala': 'hambatan',\n",
    "    'jemputan': 'penjemputan',\n",
    "    'tujuan': 'destinasi',\n",
    "    'order': 'pesanan',\n",
    "    'pesan': 'memesan',\n",
    "    'bayar': 'membayar',\n",
    "    'aman': 'aman',\n",
    "    'amanah': 'tepercaya',\n",
    "    'layanan': 'layanan',\n",
    "    'cepat': 'cepat',\n",
    "    'praktis': 'praktis',\n",
    "    'ribet': 'rumit',\n",
    "    'keluhan': 'keluhan',\n",
    "    'kelola': 'mengelola',\n",
    "    'promo': 'promosi',\n",
    "    'frekuensi': 'jumlah',\n",
    "    'stabil': 'stabil',\n",
    "    'akurat': 'tepat',\n",
    "    'jadwal': 'jadwal',\n",
    "    'estimasi': 'perkiraan',\n",
    "    'pengalaman': 'pengalaman',\n",
    "    'memuaskan': 'memuaskan',\n",
    "    'klaim': 'klaim',\n",
    "    'rating': 'penilaian',\n",
    "    'negatif': 'negatif',\n",
    "    'positif': 'positif',\n",
    "    'review': 'ulasan',\n",
    "    'pembayaran': 'pembayaran',\n",
    "    'transaksi': 'transaksi',\n",
    "    'konfirmasi': 'konfirmasi',\n",
    "    'notifikasi': 'pemberitahuan',\n",
    "    'user': 'pengguna',\n",
    "    'komplain': 'keluhan',\n",
    "    'terima': 'menerima',\n",
    "    'kirim': 'mengirim',\n",
    "    'cetak': 'mencetak',\n",
    "    'logistik': 'pengiriman',\n",
    "    'kontak': 'menghubungi',\n",
    "    'resi': 'nomor pengiriman',\n",
    "    'pelanggan': 'pelanggan',\n",
    "    'transparan': 'terbuka',\n",
    "    'penyelesaian': 'solusi',\n",
    "    'garansi': 'jaminan',\n",
    "    'pelayanan': 'layanan',\n",
    "    'responsif': 'cepat tanggap',\n",
    "    'respons': 'tanggapan',\n",
    "    'integritas': 'kejujuran',\n",
    "    'kecepatan': 'kecepatan',\n",
    "    'pengembalian': 'pengembalian',\n",
    "    'kompetitif': 'bersaing',\n",
    "    'kemudahan': 'kemudahan',\n",
    "    'fleksibel': 'mudah',\n",
    "    'tersedia': 'tersedia',\n",
    "    'sesuai': 'cocok',\n",
    "    'menyenangkan': 'menyenangkan',\n",
    "    'kekurangan': 'kekurangan',\n",
    "    'keuntungan': 'keuntungan',\n",
    "    'kerugian': 'kerugian',\n",
    "    'keperluan': 'keperluan'\n",
    "    }\n",
    "\n",
    "# mengubah kata-kata slang menjadi lebih baku dan mudah dipahami\n",
    "def slangwordsText(text):\n",
    "    words = text.split()\n",
    "    words_fixed = [slangwords[word.lower()] if word.lower() in slangwords else word for word in words]\n",
    "\n",
    "    return ' '.join(words_fixed)\n",
    "\n",
    "# unicode untuk emoticon, emoji, simbol dan lain - lain\n",
    "def emojiRemove(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"\n",
    "        \"\\U0001F300-\\U0001F5FF\"\n",
    "        \"\\U0001F680-\\U0001F6FF\"\n",
    "        \"\\U0001F700-\\U0001F77F\"\n",
    "        \"\\U0001F780-\\U0001F7FF\"\n",
    "        \"\\U0001F800-\\U0001F8FF\"\n",
    "        \"\\U0001F900-\\U0001F9FF\"\n",
    "        \"\\U0001FA00-\\U0001FA6F\"\n",
    "        \"\\U0001FA70-\\U0001FAFF\"\n",
    "        \"\\U00002702-\\U000027B0\"\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE\n",
    "    )\n",
    "\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# menghilangkan karakter spesial, whitespace dan non-whitespace\n",
    "def textCleaning(text):\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r\"http\\S+\", '', text)\n",
    "    text = re.sub(r'RT[\\s]', '', text)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text.strip()\n",
    "\n",
    "# mengubah semua text menjadi huruf kecil\n",
    "def caseFolding(text):\n",
    "    return text.lower()\n",
    "\n",
    "# pemberian token pada setiap text\n",
    "def textTokenizing(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "# penyaringan text untuk menghilangkan kata-kata umum yang tidak diperlukan\n",
    "def textFiltering(tokens):\n",
    "    stopwords_indonesia = set(stopwords.words('indonesian'))\n",
    "    stopwords_english = set(stopwords.words('english'))\n",
    "    stopwords_indonesia.update(stopwords_english)\n",
    "    return [word for word in tokens if word not in stopwords_indonesia]\n",
    "\n",
    "# menghilangkan awalan dan akhiran kata dalam bahasa indonesia dan inggris\n",
    "def textStemming(text):\n",
    "    stemmer = MPStemmer()\n",
    "    return ' '.join(stemmer.stem(word) for word in text.split())\n",
    "\n",
    "# menggabungkan kata-kata menjadi sebuah kalimat\n",
    "def toSentence(words):\n",
    "    sentences = ' '.join(word for word in words)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "# fungsi gabungan dari semua fungsi pre-processing diatas \n",
    "# kecuali toSentence untuk melihat hasil score polarity\n",
    "\n",
    "def combineFunction(text):\n",
    "    text = textCleaning(text)\n",
    "    text = emojiRemove(text)\n",
    "    text = caseFolding(text)\n",
    "    text = slangwordsText(text)\n",
    "    text = textStemming(text)\n",
    "    tokens = textTokenizing(text)\n",
    "    tokens = textFiltering(tokens)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29357\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>filtering_text</th>\n",
       "      <th>content_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad5d42d7-26b3-4b05-84d5-ec7a1630195c</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Opsi pemilihan GOFOOD \"terdekat\" sekarang kura...</td>\n",
       "      <td>2</td>\n",
       "      <td>137</td>\n",
       "      <td>4.89.1</td>\n",
       "      <td>2024-06-26 03:44:12</td>\n",
       "      <td>Hai Kak Christian, mohon maaf atas ketidaknyam...</td>\n",
       "      <td>2024-06-26 09:25:34</td>\n",
       "      <td>4.89.1</td>\n",
       "      <td>[opsi, pilih, gofood, efisien, pilih, opsi, hi...</td>\n",
       "      <td>opsi pilih gofood efisien pilih opsi hilang ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fcecd263-6061-4de6-b9f7-ecc2608922dc</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Aplikasi sudah sangat baik, tapi saya kecewa, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>4.90.2</td>\n",
       "      <td>2024-07-11 11:37:32</td>\n",
       "      <td>Hai Kak Boy, mohon maaf atas ketidaknyamananny...</td>\n",
       "      <td>2024-07-11 13:44:23</td>\n",
       "      <td>4.90.2</td>\n",
       "      <td>[aplikasi, kecewa, gojek, data, riwayat, trans...</td>\n",
       "      <td>aplikasi kecewa gojek data riwayat transaksi l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId         userName  \\\n",
       "0  ad5d42d7-26b3-4b05-84d5-ec7a1630195c  Pengguna Google   \n",
       "1  fcecd263-6061-4de6-b9f7-ecc2608922dc  Pengguna Google   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0  Opsi pemilihan GOFOOD \"terdekat\" sekarang kura...      2            137   \n",
       "1  Aplikasi sudah sangat baik, tapi saya kecewa, ...      1             57   \n",
       "\n",
       "  reviewCreatedVersion                  at  \\\n",
       "0               4.89.1 2024-06-26 03:44:12   \n",
       "1               4.90.2 2024-07-11 11:37:32   \n",
       "\n",
       "                                        replyContent           repliedAt  \\\n",
       "0  Hai Kak Christian, mohon maaf atas ketidaknyam... 2024-06-26 09:25:34   \n",
       "1  Hai Kak Boy, mohon maaf atas ketidaknyamananny... 2024-07-11 13:44:23   \n",
       "\n",
       "  appVersion                                     filtering_text  \\\n",
       "0     4.89.1  [opsi, pilih, gofood, efisien, pilih, opsi, hi...   \n",
       "1     4.90.2  [aplikasi, kecewa, gojek, data, riwayat, trans...   \n",
       "\n",
       "                                       content_clean  \n",
       "0  opsi pilih gofood efisien pilih opsi hilang ga...  \n",
       "1  aplikasi kecewa gojek data riwayat transaksi l...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menggunakan fungsi kombinasi sampai textfiltering untuk melihat score polarity\n",
    "gojek_clean_df['filtering_text'] = gojek_clean_df['content'].apply(combineFunction)\n",
    "\n",
    "# kemudian diteruskan pada fungsi untuk digabungkan menjadi kalimat\n",
    "gojek_clean_df['content_clean'] = gojek_clean_df['filtering_text'].apply(toSentence)\n",
    "\n",
    "# menampilkan panjang baris data\n",
    "print(len(gojek_clean_df))\n",
    "gojek_clean_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pemberian Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kamus untuk kata-kata positif\n",
    "positive_dictionary = dict()\n",
    "\n",
    "# import kamus positif dari github, credit to the owner: angelmetanosaa\n",
    "res = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_positive.csv')\n",
    "\n",
    "# logika jika data tidak dapat diambil\n",
    "if res.status_code == 200:\n",
    "    reader = csv.reader(StringIO(res.text), delimiter=',')\n",
    "    \n",
    "    # menambahkan kata-kata positif dan skor ke dalam positive_dictionary\n",
    "    for row in reader:\n",
    "        positive_dictionary[row[0]] = int(row[1])\n",
    "\n",
    "else:\n",
    "    print('Unable to fetch positive lexicon data')\n",
    "    \n",
    "# kamus untuk kata-kata negatif\n",
    "negative_dictionary = dict()\n",
    "\n",
    "# import kamus negatif dari github, credit to the owner: angelmetanosaa\n",
    "res = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_negative.csv')\n",
    "\n",
    "# logika jika data tidak dapat diambil\n",
    "if res.status_code == 200:\n",
    "    reader = csv.reader(StringIO(res.text), delimiter=',')\n",
    "    \n",
    "    # menambahkan kata-kata negatif dan skor ke dalam negative_dictionary\n",
    "    for row in reader:\n",
    "        negative_dictionary[row[0]] = int(row[1])\n",
    "\n",
    "else:\n",
    "    print('Unable to fetch negative lexicon data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menentukan polaritas sentimen dari data review shopee\n",
    "def analysis_sentiment(words):\n",
    "    score = 0;\n",
    "    \n",
    "    # loop untuk mencari setiap kata pada setiap kalimat\n",
    "    for word in words:\n",
    "        \n",
    "        # jika kata tersebut terdapat di dalam positive_dictionary maka score akan ditambah\n",
    "        # sesuai dengan nilai pada positive_dictionary\n",
    "        if(word in positive_dictionary):\n",
    "            score = score + positive_dictionary[word]\n",
    "        \n",
    "        # jika kata tersebut terdapat di dalam negative_dictionary maka score akan ditambah\n",
    "        # sesuai dengan nilai pada negative_dictionary\n",
    "        if(word in negative_dictionary):\n",
    "            score = score + negative_dictionary[word]\n",
    "    \n",
    "    # deklarasi variabel polarity untuk sebagai wadah nilai pada score\n",
    "    polarity = 0\n",
    "    \n",
    "    # logika score untuk menentukan nilai polarity\n",
    "    if (score > 0):\n",
    "        polarity = 2 # Positive\n",
    "    elif(score < 0 ):\n",
    "        polarity = 0 # Negative\n",
    "    else:\n",
    "        polarity = 1 # Netral\n",
    "        \n",
    "    return polarity, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity\n",
      "0    20119\n",
      "2     7294\n",
      "1     1944\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "0    opsi pilih gofood efisien pilih opsi hilang ga...\n",
      "1    aplikasi kecewa gojek data riwayat transaksi l...\n",
      "2    dear gojekmengapa aplikasi posisi kemudi titik...\n",
      "3    aplikasi bosok pesan mobil baca map jalan canc...\n",
      "4    pesan go car susah ampun jaring stabil berkali...\n",
      "Name: content_clean, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# menganalisis pada kolom filtering_text\n",
    "result = gojek_clean_df['filtering_text'].apply(analysis_sentiment)\n",
    "result = list(zip(*result))\n",
    "\n",
    "# menampilkan \n",
    "gojek_clean_df['polarity'] = result[0]\n",
    "gojek_clean_df['polarity_score'] = result[1]\n",
    "print(gojek_clean_df['polarity'].value_counts())\n",
    "print('\\n')\n",
    "print(gojek_clean_df['content_clean'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abang</th>\n",
       "      <th>abis</th>\n",
       "      <th>acc</th>\n",
       "      <th>aco</th>\n",
       "      <th>ad</th>\n",
       "      <th>admin</th>\n",
       "      <th>adu</th>\n",
       "      <th>aduh</th>\n",
       "      <th>agustus</th>\n",
       "      <th>ah</th>\n",
       "      <th>...</th>\n",
       "      <th>way</th>\n",
       "      <th>wifi</th>\n",
       "      <th>wilayah</th>\n",
       "      <th>wkwk</th>\n",
       "      <th>woi</th>\n",
       "      <th>xp</th>\n",
       "      <th>yaa</th>\n",
       "      <th>yaaa</th>\n",
       "      <th>yah</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.279123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29352</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29353</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29354</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29355</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29356</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29357 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       abang  abis  acc  aco   ad  admin  adu  aduh  agustus   ah  ...  way  \\\n",
       "0        0.0   0.0  0.0  0.0  0.0    0.0  0.0   0.0      0.0  0.0  ...  0.0   \n",
       "1        0.0   0.0  0.0  0.0  0.0    0.0  0.0   0.0      0.0  0.0  ...  0.0   \n",
       "2        0.0   0.0  0.0  0.0  0.0    0.0  0.0   0.0      0.0  0.0  ...  0.0   \n",
       "3        0.0   0.0  0.0  0.0  0.0    0.0  0.0   0.0      0.0  0.0  ...  0.0   \n",
       "4        0.0   0.0  0.0  0.0  0.0    0.0  0.0   0.0      0.0  0.0  ...  0.0   \n",
       "...      ...   ...  ...  ...  ...    ...  ...   ...      ...  ...  ...  ...   \n",
       "29352    0.0   0.0  0.0  0.0  0.0    0.0  0.0   0.0      0.0  0.0  ...  0.0   \n",
       "29353    0.0   0.0  0.0  0.0  0.0    0.0  0.0   0.0      0.0  0.0  ...  0.0   \n",
       "29354    0.0   0.0  0.0  0.0  0.0    0.0  0.0   0.0      0.0  0.0  ...  0.0   \n",
       "29355    0.0   0.0  0.0  0.0  0.0    0.0  0.0   0.0      0.0  0.0  ...  0.0   \n",
       "29356    0.0   0.0  0.0  0.0  0.0    0.0  0.0   0.0      0.0  0.0  ...  0.0   \n",
       "\n",
       "           wifi  wilayah  wkwk  woi   xp  yaa  yaaa  yah  youtube  \n",
       "0      0.000000      0.0   0.0  0.0  0.0  0.0   0.0  0.0      0.0  \n",
       "1      0.000000      0.0   0.0  0.0  0.0  0.0   0.0  0.0      0.0  \n",
       "2      0.000000      0.0   0.0  0.0  0.0  0.0   0.0  0.0      0.0  \n",
       "3      0.000000      0.0   0.0  0.0  0.0  0.0   0.0  0.0      0.0  \n",
       "4      0.279123      0.0   0.0  0.0  0.0  0.0   0.0  0.0      0.0  \n",
       "...         ...      ...   ...  ...  ...  ...   ...  ...      ...  \n",
       "29352  0.000000      0.0   0.0  0.0  0.0  0.0   0.0  0.0      0.0  \n",
       "29353  0.000000      0.0   0.0  0.0  0.0  0.0   0.0  0.0      0.0  \n",
       "29354  0.000000      0.0   0.0  0.0  0.0  0.0   0.0  0.0      0.0  \n",
       "29355  0.000000      0.0   0.0  0.0  0.0  0.0   0.0  0.0      0.0  \n",
       "29356  0.000000      0.0   0.0  0.0  0.0  0.0   0.0  0.0      0.0  \n",
       "\n",
       "[29357 rows x 1000 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# membagi data konten dan fitur\n",
    "X = gojek_clean_df['content_clean']\n",
    "Y = gojek_clean_df['polarity']\n",
    "\n",
    "# memberikan nilai setiap fitur dengan teknik TF-IDF\n",
    "tf_idf = TfidfVectorizer(max_features=1000, min_df=17, max_df=0.8)\n",
    "X_tf_idf = tf_idf.fit_transform(X)\n",
    "\n",
    "# mengubah vektor menjadi Dataframe\n",
    "features_df = pd.DataFrame(X_tf_idf.toarray(), columns=tf_idf.get_feature_names_out())\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape:  (23485, 1000) (23485,)\n",
      "Test Data Shape:  (5872, 1000) (5872,)\n"
     ]
    }
   ],
   "source": [
    "# membagi data latih dan uji dengan fungsi train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tf_idf.toarray(), Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Train Data Shape: ', X_train.shape, y_train.shape)\n",
    "print('Test Data Shape: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Mechine Learning menggunakan arsitektur RNN 3 macam variasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback untuk menghentikan training jika tidak ada peningkatan\n",
    "early_stopping = EarlyStopping(\n",
    "    restore_best_weights=True,\n",
    "    patience=3,\n",
    "    min_delta=0.01,\n",
    "    monitor='val_loss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback untuk mengurangi learning rate jika validation loss tidak membaik dalam beberapa epoch\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 38ms/step - accuracy: 0.6093 - loss: 0.8893 - val_accuracy: 0.8258 - val_loss: 0.4442 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - accuracy: 0.8465 - loss: 0.4274 - val_accuracy: 0.8599 - val_loss: 0.3620 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 36ms/step - accuracy: 0.8754 - loss: 0.3477 - val_accuracy: 0.8680 - val_loss: 0.3424 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 37ms/step - accuracy: 0.8888 - loss: 0.3021 - val_accuracy: 0.8684 - val_loss: 0.3497 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 35ms/step - accuracy: 0.9016 - loss: 0.2709 - val_accuracy: 0.8648 - val_loss: 0.3839 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 38ms/step - accuracy: 0.9130 - loss: 0.2477 - val_accuracy: 0.8689 - val_loss: 0.3611 - learning_rate: 0.0010\n",
      "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\n",
      "\n",
      "Train Accuracy:  0.9037683627847563\n",
      "Test Accuracy:  0.8690395095367848\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93      4043\n",
      "           1       0.00      0.00      0.00       383\n",
      "           2       0.80      0.84      0.82      1446\n",
      "\n",
      "    accuracy                           0.87      5872\n",
      "   macro avg       0.56      0.60      0.58      5872\n",
      "weighted avg       0.81      0.87      0.84      5872\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vega\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vega\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vega\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Model 1 menggunakan arsitektur RNN\n",
    "Model_1 = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(1080, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Mengatur optimizer, loss dan metrics yang akan di tampilkan\n",
    "Model_1.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Melatih Model RNN\n",
    "hist_accuracy_1 = Model_1.fit(\n",
    "    X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Memprediksi model dengan data latih dan uji\n",
    "y_pred_train_1 = Model_1.predict(X_train)\n",
    "y_pred_test_1 = Model_1.predict(X_test)\n",
    "\n",
    "# Konversi prediksi ke label\n",
    "y_pred_train_labels_1 = y_pred_train_1.argmax(axis=1)\n",
    "y_pred_test_labels_1 = y_pred_test_1.argmax(axis=1)\n",
    "\n",
    "# Menghitung akurasi skor berdasarkan nilai prediksi data latih dan uji\n",
    "accuracy_train_1 = accuracy_score(y_train, y_pred_train_labels_1)\n",
    "accuracy_test_1 = accuracy_score(y_test, y_pred_test_labels_1)\n",
    "\n",
    "# Menampilkan hasil akurasi \n",
    "print('\\n\\nTrain Accuracy: ', accuracy_train_1)\n",
    "print('Test Accuracy: ', accuracy_test_1)\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred_test_labels_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.6446 - loss: 0.8381 - val_accuracy: 0.8595 - val_loss: 0.3750 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.8531 - loss: 0.4117 - val_accuracy: 0.8743 - val_loss: 0.3351 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.8654 - loss: 0.3603 - val_accuracy: 0.8888 - val_loss: 0.3089 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.8807 - loss: 0.3183 - val_accuracy: 0.8857 - val_loss: 0.3131 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.8947 - loss: 0.2881 - val_accuracy: 0.8879 - val_loss: 0.3200 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9018 - loss: 0.2715 - val_accuracy: 0.8917 - val_loss: 0.3133 - learning_rate: 0.0010\n",
      "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\n",
      "\n",
      "Train Accuracy:  0.9208005109644454\n",
      "Test Accuracy:  0.8887942779291553\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      4043\n",
      "           1       0.56      0.22      0.32       383\n",
      "           2       0.79      0.90      0.84      1446\n",
      "\n",
      "    accuracy                           0.89      5872\n",
      "   macro avg       0.76      0.69      0.70      5872\n",
      "weighted avg       0.88      0.89      0.88      5872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 2 menggunakan arsitektur RNN\n",
    "Model_2 = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Mengatur optimizer, loss dan metrics yang akan di tampilkan\n",
    "Model_2.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Melatih Model RNN\n",
    "hist_accuracy_2 = Model_2.fit(\n",
    "    X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Memprediksi model dengan data latih dan uji\n",
    "y_pred_train_2 = Model_2.predict(X_train)\n",
    "y_pred_test_2 = Model_2.predict(X_test)\n",
    "\n",
    "# Konversi prediksi ke label\n",
    "y_pred_train_labels_2 = y_pred_train_2.argmax(axis=1)\n",
    "y_pred_test_labels_2 = y_pred_test_2.argmax(axis=1)\n",
    "\n",
    "# Menghitung akurasi skor berdasarkan nilai prediksi data latih dan uji\n",
    "accuracy_train_2 = accuracy_score(y_train, y_pred_train_labels_2)\n",
    "accuracy_test_2 = accuracy_score(y_test, y_pred_test_labels_2)\n",
    "\n",
    "# Menampilkan hasil akurasi \n",
    "print('\\n\\nTrain Accuracy: ', accuracy_train_2)\n",
    "print('Test Accuracy: ', accuracy_test_2)\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred_test_labels_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.7512 - loss: 0.6087 - val_accuracy: 0.8557 - val_loss: 0.3829 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.8765 - loss: 0.3424 - val_accuracy: 0.8697 - val_loss: 0.3550 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m783/783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.9059 - loss: 0.2660 - val_accuracy: 0.8744 - val_loss: 0.3386 - learning_rate: 0.0010\n",
      "\u001b[1m734/734\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\n",
      "\n",
      "Train Accuracy:  0.8822226953374495\n",
      "Test Accuracy:  0.8647820163487738\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93      4043\n",
      "           1       0.68      0.10      0.17       383\n",
      "           2       0.72      0.91      0.80      1446\n",
      "\n",
      "    accuracy                           0.86      5872\n",
      "   macro avg       0.78      0.64      0.63      5872\n",
      "weighted avg       0.86      0.86      0.85      5872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 3 menggunakan arsitektur RNN\n",
    "Model_3 = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(300, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Mengatur optimizer, loss dan metrics yang akan di tampilkan\n",
    "Model_3.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Melatih Model RNN\n",
    "hist_accuracy_3 = Model_3.fit(\n",
    "    X_train, y_train, epochs=20, batch_size=24, validation_split=0.2, callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Memprediksi model dengan data latih dan uji\n",
    "y_pred_train_3 = Model_3.predict(X_train)\n",
    "y_pred_test_3 = Model_3.predict(X_test)\n",
    "\n",
    "# Konversi prediksi ke label\n",
    "y_pred_train_labels_3 = y_pred_train_3.argmax(axis=1)\n",
    "y_pred_test_labels_3 = y_pred_test_3.argmax(axis=1)\n",
    "\n",
    "# Menghitung akurasi skor berdasarkan nilai prediksi data latih dan uji\n",
    "accuracy_train_3 = accuracy_score(y_train, y_pred_train_labels_3)\n",
    "accuracy_test_3 = accuracy_score(y_test, y_pred_test_labels_3)\n",
    "\n",
    "# Menampilkan hasil akurasi \n",
    "print('\\n\\nTrain Accuracy: ', accuracy_train_3)\n",
    "print('Test Accuracy: ', accuracy_test_3)\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred_test_labels_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil Akhir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model  Accuracy Test\n",
      "1  Model_2       0.888794\n",
      "0  Model_1       0.869040\n",
      "2  Model_3       0.864782\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    'Model': ['Model_1', 'Model_2', 'Model_3'],\n",
    "    'Accuracy Train': [accuracy_train_1, accuracy_train_2, accuracy_train_3],\n",
    "    'Accuracy Test': [accuracy_test_1, accuracy_test_2, accuracy_test_3]\n",
    "})\n",
    "\n",
    "accuracy_test_all = result_df[['Model', 'Accuracy Test']]\n",
    "print(accuracy_test_all.sort_values(by='Accuracy Test', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing analisis sentimen realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aplikasi nya banyak error dan juga bug, kadang juga suka keluar sendiri dan loadingnya lama, aplikasinya buruk\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759ms/step\n",
      "Sentimen dari kalimat tersebut adalah: NEGATIF\n"
     ]
    }
   ],
   "source": [
    "# memasukan value kata atau kalimat dari pengguna\n",
    "data_new = input('Masukan Kalimat Baru: ')\n",
    "print(data_new)\n",
    "\n",
    "# pre-processing pada data_new\n",
    "data_new_filtering = combineFunction(data_new)\n",
    "data_new_cleaned = toSentence(data_new_filtering)\n",
    "\n",
    "# Menggunakan objek tfidf yang sudah di-fit dari pelatihan sebelumnya\n",
    "X_data_new = tf_idf.transform([data_new_cleaned])\n",
    "\n",
    "# Memprediksi sentimen menggunakan Model_2: karena model ini yang memiliki akurasi paling tinggi\n",
    "sentimen_predict = Model_2.predict(X_data_new)\n",
    "\n",
    "# Mendapatkan indeks kelas dengan probabilitas tertinggi\n",
    "predicted_class = sentimen_predict.argmax(axis=1)[0]\n",
    "\n",
    "# menampilkan hasil prediksi sesuai dengan score yang didapatkan\n",
    "if predicted_class == 2:\n",
    "    print('Sentimen dari kalimat tersebut adalah: POSITIF')\n",
    "elif predicted_class== 0:\n",
    "    print('Sentimen dari kalimat tersebut adalah: NEGATIF')\n",
    "else:\n",
    "    print('Sentimen dari kalimat tersebut adalah: NETRAL')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
